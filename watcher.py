import os
import time
import json
import re
import psutil
import requests
import psycopg2
from psycopg2 import sql
from datetime import datetime

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
from dotenv import load_dotenv
load_dotenv()

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è. IP –∞–¥—Ä–µ—Å –Ω—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –≤–∞—à, —ç—Ç–æ –±—É–¥–µ—Ç –∞–¥—Ä–µ—Å –≤–∞—à–µ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞. –ü–æ—Ä—Ç—ã LM
# —Å–º–æ—Ç—Ä–∏—Ç–µ —Ç–∞–∫ –∂–µ –ø–æ–¥ –≤–∞—à –ø—Ä–æ–µ–∫—Ç, –ø–æ—Ä—Ç 8080 –≤ –º–æ–µ–º —Å–ª—É—á–∞–µ –≤—ã–±—Ä–∞–Ω –¥–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞, —Ç–∞–∫ –∫–∞–∫ —Ä–∞–Ω–µ–µ –≤ –ø—Ä–æ–µ–∫—Ç–µ
# –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª –°—É–ø–µ—Ä—Å–µ—Ç
UNC_PATH = os.getenv('SMB_SHARE', r'\\192.168.1.6\transcription-queue') 
LM_BASE_URL = os.getenv('LM_STUDIO_URL', 'http://localhost:8080')

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
db_config = {
    'host': os.getenv('DB_HOST', '192.168.1.6'),
    'port': int(os.getenv('DB_PORT', '5432')),
    'database': os.getenv('DB_NAME', 'whisper_db'),
    'user': os.getenv('DB_USER', 'whisper_user'),
    'password': os.getenv('DB_PASSWORD')
}

# –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ Mistral 7B - —ç—Ç–∞ –º–æ–¥–µ–ª—å –≤–ª–µ–∑–∞–µ—Ç –≤ –º–æ—é –ø–∞–º—è—Ç—å, –ø–ª—é—Å —Ö–æ—Ä–æ—à–∞ –≤ —Ç–µ–∫—Å—Ç–µ, –∫–∞–∫ –≤–∞—Ä–∏–∞–Ω—Ç –º–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å
# Phi –æ—Ç –ú–∞–π–∫—Ä–æ—Å–æ—Ñ—Ç, –æ –Ω–µ–π —Ç–æ–∂–µ —Ö–æ—Ä–æ—à–∏–µ –æ—Ç–∑—ã–≤—ã –∏–º–µ–Ω–Ω–æ –ø—Ä–æ —Ä–∞–±–æ—Ç—É —Å —Ç–µ–∫—Å—Ç–æ–º, –∫–æ–∏–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∏ —è–≤—è–ª–µ—Ç—Å—è
LM_MODEL_NAME = "Mistral-7B-Instruct-v0.3-Q4_K_M.gguf"

def contains_russian(text):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç —Ä—É—Å—Å–∫–∏–µ –±—É–∫–≤—ã"""
    russian_letters = set('–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è')
    text_lower = text.lower()
    return any(char in russian_letters for char in text_lower)

def check_lm_studio():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ LM Studio"""
    try:
        response = requests.get(f"{LM_BASE_URL}/v1/models", timeout=10)
        return response.status_code == 200
    except Exception as e:
        print(f"LM Studio –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
        return False

def clean_lm_response(response_text):
    """–û—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ LM Studio –æ—Ç markdown —Ä–∞–∑–º–µ—Ç–∫–∏"""
    if not response_text:
        return None
    
    # –£–±–∏—Ä–∞–µ–º –æ–±—Ä–∞—Ç–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –∏ markdown
    text = response_text.strip()
    
    # –£–¥–∞–ª—è–µ–º ```json –∏ ``` –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ
    if text.startswith('```json'):
        text = text[7:].strip()
    elif text.startswith('```'):
        text = text[3:].strip()
    
    if text.endswith('```'):
        text = text[:-3].strip()
    
    # –£–±–∏—Ä–∞–µ–º –ª—é–±—ã–µ –¥—Ä—É–≥–∏–µ –æ—Å—Ç–∞—Ç–∫–∏ —Ä–∞–∑–º–µ—Ç–∫–∏
    text = re.sub(r'^```.*?```', '', text, flags=re.DOTALL)
    text = text.strip()
    
    # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ JSON –≤ —Ç–µ–∫—Å—Ç–µ
    json_match = re.search(r'\{[\s\S]*\}', text)
    if json_match:
        return json_match.group()
    
    return text

def analyze_with_lm_studio(text):
    """–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é LM Studio –∏ Mistral 7B"""
    try:
        api_url = f"{LM_BASE_URL}/v1/chat/completions"
        
        # –†–£–°–°–ö–û–Ø–ó–´–ß–ù–´–ô –ü–†–û–ú–ü–¢ –° –ì–ê–†–ê–ù–¢–ò–ï–ô –†–£–°–°–ö–û–ì–û –û–¢–í–ï–¢–ê
        russian_prompt = """[INST] –¢—ã - —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤. 

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∏ –≤–µ—Ä–Ω–∏ –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å—Ç—Ä–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.

–ñ–ï–°–¢–ö–ò–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:
1. –í–°–ï —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞ –†–£–°–°–ö–û–ú —è–∑—ã–∫–µ
2. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –∫–∏—Ä–∏–ª–ª–∏—Ü—É
3. –ù–∏–∫–∞–∫–æ–≥–æ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –≤ –æ—Ç–≤–µ—Ç–µ
4. –¢–æ–ª—å–∫–æ JSON –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
5. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π markdown —Ä–∞–∑–º–µ—Ç–∫—É

–°—Ç—Ä—É–∫—Ç—É—Ä–∞ JSON:
{
  "sentiment": "–ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π/–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π/–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π",
  "key_topics": ["—Ç–µ–º–∞ –æ–±—Å—É–∂–¥–µ–Ω–∏—è 1", "—Ç–µ–º–∞ –æ–±—Å—É–∂–¥–µ–Ω–∏—è 2"],
  "action_items": ["–Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ 1", "–Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ 2"],
  "summary": "–ø–æ–ª–Ω–æ–µ –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ",
  "call_quality": "—Ö–æ—Ä–æ—à–∏–π/—Å—Ä–µ–¥–Ω–∏–π/–ø–ª–æ—Ö–æ–π"
}

–í–µ—Ä–Ω–∏ –æ—Ç–≤–µ—Ç —Å—Ç—Ä–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ! [/INST]

–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:"""
        
        payload = {
            "model": LM_MODEL_NAME,
            "messages": [
                {
                    "role": "user", 
                    "content": f"{russian_prompt}\n\n{text}\n\n–í–µ—Ä–Ω–∏ JSON –æ—Ç–≤–µ—Ç —Å—Ç—Ä–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ:"
                }
            ],
            "temperature": 0.1,
            "max_tokens": 4000,
            "top_p": 0.9,
            "stream": False
        }
        
        print(f"üì® –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LM Studio —Å –º–æ–¥–µ–ª—å—é: {LM_MODEL_NAME}")
        response = requests.post(api_url, json=payload, timeout=600)  # 10 –º–∏–Ω—É—Ç —Ç–∞–π–º–∞—É—Ç
        
        if response.status_code == 200:
            result = response.json()
            analysis_result = result['choices'][0]['message']['content']
            
            # –û—á–∏—â–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç markdown
            cleaned_response = clean_lm_response(analysis_result)
            
            if not cleaned_response:
                print(f"‚ùå –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç LM Studio")
                return None
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è JSON
            try:
                json_data = json.loads(cleaned_response)
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
                if not contains_russian(cleaned_response):
                    print("‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –æ—Ç–≤–µ—Ç –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —Ç–µ–∫—Å—Ç")
                else:
                    print(f"‚úÖ Mistral 7B –≤–µ—Ä–Ω—É–ª —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π JSON")
                
                return json.dumps(json_data, ensure_ascii=False, indent=2)
            except json.JSONDecodeError as e:
                print(f"‚ùå –û—Ç–≤–µ—Ç –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≤–∞–ª–∏–¥–Ω—ã–º JSON: {e}")
                print(f"Raw response: {analysis_result[:200]}...")
                return None
                
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ HTTP {response.status_code}: {response.text}")
            return None
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return None

def split_long_text(text, max_tokens=3000):
    """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è Mistral 7B"""
    words = text.split()
    chunks = []
    current_chunk = []
    current_length = 0
    
    for word in words:
        # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ (1 —Å–ª–æ–≤–æ ‚âà 1.3 —Ç–æ–∫–µ–Ω–∞)
        if current_length + len(word) * 1.3 > max_tokens:
            chunks.append(' '.join(current_chunk))
            current_chunk = []
            current_length = 0
        
        current_chunk.append(word)
        current_length += len(word) * 1.3
    
    if current_chunk:
        chunks.append(' '.join(current_chunk))
    
    return chunks

def analyze_long_text(text):
    """–ê–Ω–∞–ª–∏–∑ –¥–ª–∏–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –ø–æ —á–∞—Å—Ç—è–º"""
    chunks = split_long_text(text, max_tokens=3000)
    all_results = []
    
    for i, chunk in enumerate(chunks):
        print(f"üìÑ –ê–Ω–∞–ª–∏–∑ —á–∞—Å—Ç–∏ {i+1}/{len(chunks)} ({(i+1)/len(chunks)*100:.1f}%)...")
        result = analyze_with_lm_studio(chunk)
        if result:
            try:
                result_data = json.loads(result)
                all_results.append(result_data)
            except:
                all_results.append({"chunk": i+1, "error": "invalid_json"})
        time.sleep(2)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
    if all_results:
        return json.dumps({
            "combined_analysis": all_results,
            "total_chunks": len(chunks),
            "combined_summary": "–ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω –ø–æ —á–∞—Å—Ç—è–º –∏–∑-–∑–∞ –±–æ–ª—å—à–æ–≥–æ –æ–±—ä–µ–º–∞ —Ç–µ–∫—Å—Ç–∞"
        }, ensure_ascii=False)
    
    return None

def get_db_connection():
    """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö"""
    try:
        conn = psycopg2.connect(**db_config)
        return conn
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
        return None

def save_analysis_to_db(transcription_id, analysis_result):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
    conn = get_db_connection()
    if not conn:
        return False
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å JSON –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
        analysis_data = json.loads(analysis_result)
        
        with conn.cursor() as cur:
            # –û–ë–ù–û–í–õ–ï–ù–ù–´–ô –ó–ê–ü–†–û–° –° model_used
            cur.execute("""
                INSERT INTO transcription_analysis 
                (transcription_id, analysis_result, analysis_date, model_used) 
                VALUES (%s, %s, %s, %s)
            """, (transcription_id, analysis_result, datetime.now(), LM_MODEL_NAME))
            conn.commit()
        
        print(f"üíæ –ê–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –ë–î –¥–ª—è transcription_id: {transcription_id}")
        return True
        
    except json.JSONDecodeError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: analysis_result –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≤–∞–ª–∏–¥–Ω—ã–º JSON: {e}")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î: {e}")
        conn.rollback()
        return False
    finally:
        conn.close()

def process_task(task_path, task_id, transcription_id):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–π –∑–∞–¥–∞—á–∏"""
    try:
        with open(task_path, 'r', encoding='utf-8') as f:
            task_data = json.load(f)
        
        text = task_data.get('text', '')
        if not text or len(text.strip()) < 10:
            print(f"‚ö†Ô∏è –ü—É—Å—Ç–æ–π –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç –≤ –∑–∞–¥–∞—á–µ {task_id}")
            return False
        
        text_length = len(text)
        print(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–¥–∞—á—É {task_id}, –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {text_length} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å LM Studio
        if not check_lm_studio():
            print("‚ùå LM Studio –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–¥–∞—á—É")
            return False
        
        print("‚úÖ LM Studio –¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑...")
        
        # –í—ã–±–∏—Ä–∞–µ–º –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞
        if text_length > 8000:  # –î–ª–∏–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ —á–∞—Å—Ç—è–º
            print("üìñ –¢–µ–∫—Å—Ç –¥–ª–∏–Ω–Ω—ã–π, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ —á–∞—Å—Ç—è–º...")
            analysis_result = analyze_long_text(text)
        else:  # –ö–æ—Ä–æ—Ç–∫–∏–µ —Ç–µ–∫—Å—Ç—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ü–µ–ª–∏–∫–æ–º
            analysis_result = analyze_with_lm_studio(text)
        
        if not analysis_result:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–¥–∞—á—É {task_id}")
            return False
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        if save_analysis_to_db(transcription_id, analysis_result):
            print(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ –ë–î")
            return True
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ {task_id} –≤ –ë–î")
            return False
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á–∏ {task_id}: {e}")
        return False

def ensure_directories_exist():
    """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –µ—Å–ª–∏ –æ–Ω–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç"""
    directories = [
        os.path.join(UNC_PATH, 'pending'),
        os.path.join(UNC_PATH, 'processing'), 
        os.path.join(UNC_PATH, 'completed'),
        os.path.join(UNC_PATH, 'failed')
    ]
    
    for directory in directories:
        if not os.path.exists(directory):
            try:
                os.makedirs(directory)
                print(f"üìÅ –°–æ–∑–¥–∞–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {directory}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {directory}: {e}")
                return False
    return True

def main():
    print("=" * 70)
    print("üöÄ –ó–∞–ø—É—Å–∫ Transcription Watcher —Å Mistral 7B")
    print("=" * 70)
    print(f"üì° LM Studio URL: {LM_BASE_URL}")
    print(f"üß† –ú–æ–¥–µ–ª—å: {LM_MODEL_NAME}")
    print(f"üìÇ SMB Share: {UNC_PATH}")
    print(f"üóÑÔ∏è DB Host: {db_config['host']}")
    print("=" * 70)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π
    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π...")
    if not check_lm_studio():
        print("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: LM Studio –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω!")
        print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ LM Studio –∑–∞–ø—É—â–µ–Ω –Ω–∞ http://localhost:8080")
        print("–ò —á—Ç–æ –º–æ–¥–µ–ª—å Mistral 7B –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    else:
        print("‚úÖ LM Studio –¥–æ—Å—Ç—É–ø–µ–Ω")
    
    if not ensure_directories_exist():
        print("‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π")
        return
    
    print("üëÇ Watcher –∑–∞–ø—É—â–µ–Ω, –æ–∂–∏–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á...")
    print("–ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏")
    print("=" * 70)
    
    while True:
        try:
            pending_dir = os.path.join(UNC_PATH, 'pending')
            processing_dir = os.path.join(UNC_PATH, 'processing')
            completed_dir = os.path.join(UNC_PATH, 'completed')
            failed_dir = os.path.join(UNC_PATH, 'failed')
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ pending
            task_files = [f for f in os.listdir(pending_dir) if f.endswith('.json')]
            
            if task_files:
                print(f"üìã –ù–∞–π–¥–µ–Ω–æ –∑–∞–¥–∞—á: {len(task_files)}")
            
            for task_file in task_files:
                task_path = os.path.join(pending_dir, task_file)
                processing_path = os.path.join(processing_dir, task_file)
                
                try:
                    # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –≤ processing
                    os.rename(task_path, processing_path)
                    
                    with open(processing_path, 'r', encoding='utf-8') as f:
                        task_data = json.load(f)
                    
                    task_id = task_data.get('task_id', 'unknown')
                    transcription_id = task_data.get('transcription_id')
                    
                    print(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏: {task_id}")
                    
                    success = process_task(processing_path, task_id, transcription_id)
                    
                    # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –≤ completed –∏–ª–∏ failed
                    if success:
                        completed_path = os.path.join(completed_dir, task_file)
                        os.rename(processing_path, completed_path)
                        print(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                    else:
                        failed_path = os.path.join(failed_dir, task_file)
                        os.rename(processing_path, failed_path)
                        print(f"‚ùå –ó–∞–¥–∞—á–∞ {task_id} –ø–µ—Ä–µ–º–µ—â–µ–Ω–∞ –≤ failed")
                        
                except Exception as e:
                    print(f"‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Å –∑–∞–¥–∞—á–µ–π {task_file}: {e}")
                    # –ü—ã—Ç–∞–µ–º—Å—è –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å –≤ failed –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
                    try:
                        failed_path = os.path.join(failed_dir, task_file)
                        if os.path.exists(processing_path):
                            os.rename(processing_path, failed_path)
                        elif os.path.exists(task_path):
                            os.rename(task_path, failed_path)
                    except:
                        pass
            
            # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π
            time.sleep(15)
            
        except KeyboardInterrupt:
            print("\nüõë Watcher –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            break
        except Exception as e:
            print(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ: {e}")
            time.sleep(30)

if __name__ == "__main__":
    main()